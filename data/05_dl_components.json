{
  "chapter_id": "05",
  "chapter_title": "ディープラーニングの要素技術",
  "terms": [
    {
      "term": "全結合層（Fully Connected Layer）",
      "reading": "ぜんけつごうそう",
      "definition": "すべての入力がすべての出力につながる層。情報をまとめて判断する役割を持つ。",
      "example": "画像分類の最後の層で使われる。",
      "category": "層の種類"
    },
    {
      "term": "重み（Weight）",
      "reading": "おもみ",
      "definition": "AIが『どの情報をどれくらい重要と考えるか』を表す数値。学習によって自動で調整される。",
      "example": "料理の味付けで塩を多めにするような調整。",
      "category": "パラメータ"
    },
    {
      "term": "バイアス（Bias）",
      "reading": "ばいあす",
      "definition": "出力に少し足したり引いたりする調整値。モデルの柔軟性を高める。",
      "example": "料理の最後に少し塩を足すような微調整。",
      "category": "パラメータ"
    },
    {
      "term": "畳み込み層（Convolution Layer）",
      "reading": "たたみこみそう",
      "definition": "画像の特徴（線・角・模様など）を抽出する層。小さなフィルタを画像にスライドさせて特徴を見つける。",
      "example": "猫の耳や目の形などを自動で見つける。",
      "category": "畳み込み"
    },
    {
      "term": "フィルタ（カーネル）",
      "reading": "ふぃるた",
      "definition": "画像の一部分をチェックするための小さな窓。畳み込みで使われる。",
      "example": "スタンプのように画像の上を押して特徴を拾う。",
      "category": "畳み込み"
    },
    {
      "term": "ストライド（Stride）",
      "reading": "すとらいど",
      "definition": "フィルタをどれくらいの幅で動かすかを決める値。",
      "example": "虫眼鏡を1cmずつ動かすか、3cmずつ動かすかの違い。",
      "category": "畳み込み"
    },
    {
      "term": "パディング（Padding）",
      "reading": "ぱでぃんぐ",
      "definition": "画像の周りに余白をつけて、端の情報も扱えるようにする方法。",
      "example": "ノートの端に余白をつけて書きやすくするイメージ。",
      "category": "畳み込み"
    },
    {
      "term": "プーリング層（Pooling Layer）",
      "reading": "ぷーりんぐそう",
      "definition": "特徴マップを縮小し、重要な情報だけ残す層。計算量を減らす役割がある。",
      "example": "写真を縮小しても何が写っているか分かるのと同じ。",
      "category": "プーリング"
    },
    {
      "term": "最大値プーリング（Max Pooling）",
      "reading": "まっくすぷーりんぐ",
      "definition": "小さな領域の中で最も強い特徴（最大値）だけを残す方法。",
      "example": "クラスで一番背が高い人だけ記録するイメージ。",
      "category": "プーリング"
    },
    {
      "term": "平均値プーリング（Average Pooling）",
      "reading": "へいきんちぷーりんぐ",
      "definition": "領域の平均値を取る方法。全体の傾向をなめらかにする。",
      "example": "クラス全員の平均身長を出すイメージ。",
      "category": "プーリング"
    },
    {
      "term": "グローバル平均プーリング（GAP）",
      "reading": "ぐろーばるへいきんぷーりんぐ",
      "definition": "特徴マップ全体の平均を1つの値にする方法。最終層の前でよく使われる。",
      "example": "写真全体の明るさの平均を1つの数字にする。",
      "category": "プーリング"
    },
    {
      "term": "スキップ結合（Skip Connection）",
      "reading": "すきっぷけつごう",
      "definition": "途中の層を飛ばして前の情報を後ろの層に直接渡す仕組み。深いネットワークでも学習が安定する。",
      "example": "長い会議で最初の結論だけ先に伝えるショートカット。",
      "category": "ネットワーク構造"
    },
    {
      "term": "残差ブロック（Residual Block）",
      "reading": "ざんさぶろっく",
      "definition": "スキップ結合を使って学習しやすくした構造。ResNetで使われる。",
      "example": "階段を一段ずつ登るのではなく、踏み台を使って楽に登るイメージ。",
      "category": "ネットワーク構造"
    },
    {
      "term": "正規化層（Normalization Layer）",
      "reading": "せいきかそう",
      "definition": "データのばらつきを整えて学習を安定させる層。",
      "example": "データを平均0・ばらつき1に揃える。",
      "category": "正規化"
    },
    {
      "term": "バッチ正規化（Batch Normalization）",
      "reading": "ばっちせいきか",
      "definition": "ミニバッチ単位でデータを正規化する方法。学習を安定させる。",
      "example": "クラス全員の点数を平均0に揃えるイメージ。",
      "category": "正規化"
    },
    {
      "term": "レイヤー正規化（Layer Normalization）",
      "reading": "れいやーせいきか",
      "definition": "1つのデータの中で正規化を行う方法。RNNなどで使われる。",
      "example": "1人の成績だけを平均0に揃えるイメージ。",
      "category": "正規化"
    },
    {
      "term": "グループ正規化（Group Normalization）",
      "reading": "ぐるーぷせいきか",
      "definition": "チャンネルをグループに分けて正規化する方法。小さなバッチでも安定する。",
      "example": "クラスを小グループに分けて平均を揃えるイメージ。",
      "category": "正規化"
    },
    {
      "term": "ディラテッド畳み込み（Dilated Convolution）",
      "reading": "でぃらてっどたたみこみ",
      "definition": "フィルタの間に隙間をあけて広い範囲を見られるようにする畳み込み。",
      "example": "虫眼鏡を少し浮かせて広い範囲を見るイメージ。",
      "category": "特殊な畳み込み"
    },
    {
      "term": "深さ方向分離畳み込み（Depthwise Separable Convolution）",
      "reading": "ふかさほうこうぶんりたたみこみ",
      "definition": "畳み込みを2段階に分けて計算を軽くする方法。モバイル向けモデルで使われる。",
      "example": "野菜を切る→混ぜるを別々に行う効率化。",
      "category": "特殊な畳み込み"
    },
    {
      "term": "オートエンコーダ（Autoencoder）",
      "reading": "おーとえんこーだ",
      "definition": "データを圧縮して復元することで特徴を学ぶモデル。",
      "example": "写真を小さく保存してから元に戻すイメージ。",
      "category": "生成モデル"
    },
    {
      "term": "変分オートエンコーダ（VAE）",
      "reading": "ぶいえーいー",
      "definition": "圧縮した空間を確率的に扱い、新しいデータを生成できるモデル。",
      "example": "似ているけれど少し違う画像を作れるコピー機。",
      "category": "生成モデル"
    },
    {
      "term": "データ拡張（Data Augmentation）",
      "reading": "でーたかくちょう",
      "definition": "学習データを人工的に増やす方法。回転・反転・明るさ変更など。",
      "example": "写真をいろんな角度で撮り直して練習量を増やす。",
      "category": "データ拡張"
    },
    {
      "term": "Mixup",
      "reading": "みっくさっぷ",
      "definition": "2つの画像を混ぜて新しい学習データを作る手法。",
      "example": "猫と犬の画像を半分ずつ混ぜる。",
      "category": "データ拡張"
    },
    {
      "term": "Cutout",
      "reading": "かっとあうと",
      "definition": "画像の一部を黒く塗りつぶして学習させる手法。",
      "example": "視界をわざと狭めて練習するような負荷トレーニング。",
      "category": "データ拡張"
    },
    {
      "term": "Random Erasing",
      "reading": "らんだむいれーしんぐ",
      "definition": "画像の一部をランダムに消して学習させる手法。",
      "example": "写真の一部が隠れていても認識できるようにする。",
      "category": "データ拡張"
    }
  ]
}
