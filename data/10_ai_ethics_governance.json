{
  "chapter_id": "10",
  "chapter_title": "AI倫理・AIガバナンス",
  "terms": [
    {
      "term": "AI倫理",
      "reading": "えーあいりんり",
      "definition": "AIを使うときに、人を傷つけない・不公平にしないための考え方。",
      "example": "採用AIが女性ばかり不採用にするのはNG。",
      "category": "倫理"
    },
    {
      "term": "公平性（Fairness）",
      "reading": "こうへいせい",
      "definition": "AIが特定の人を不当に差別しないようにすること。",
      "example": "住所や性別だけで不利にしない。",
      "category": "公平性"
    },
    {
      "term": "透明性（Transparency）",
      "reading": "とうめいせい",
      "definition": "AIがどんなデータを使い、どう判断しているかを明確にすること。",
      "example": "AIの判断基準を公開する。",
      "category": "透明性"
    },
    {
      "term": "説明可能性（Explainability / XAI）",
      "reading": "せつめいかのうせい",
      "definition": "AIの判断理由を人間が理解できる形で説明できること。",
      "example": "『不採用の理由は経験年数が基準に満たなかったため』など。",
      "category": "説明可能性"
    },
    {
      "term": "アカウンタビリティ",
      "reading": "あかうんたびりてぃ",
      "definition": "AIの結果に対して誰が責任を持つかを明確にすること。",
      "example": "AIの誤判定時の責任者を決める。",
      "category": "責任"
    },
    {
      "term": "プライバシー保護",
      "reading": "ぷらいばしーほご",
      "definition": "個人の情報が勝手に使われたり漏れたりしないように守ること。",
      "example": "顔写真を許可なくAI学習に使わない。",
      "category": "プライバシー"
    },
    {
      "term": "バイアス（Bias）",
      "reading": "ばいあす",
      "definition": "データの偏りによってAIが不公平な判断をしてしまうこと。",
      "example": "男性のデータばかりで学習すると女性に不利なAIになる。",
      "category": "公平性"
    },
    {
      "term": "ディープフェイク（Deepfake）",
      "reading": "でぃーぷふぇいく",
      "definition": "AIで作られた本物そっくりの偽動画・偽画像。",
      "example": "なりすましやフェイクニュースに悪用される。",
      "category": "社会的影響"
    },
    {
      "term": "フィルターバブル",
      "reading": "ふぃるたーばぶる",
      "definition": "AIがユーザーの好きな情報だけを見せ続けることで、世界が偏って見える現象。",
      "example": "SNSで自分と同じ意見ばかり表示される。",
      "category": "社会的影響"
    },
    {
      "term": "エコーチェンバー",
      "reading": "えこーちぇんばー",
      "definition": "同じ意見ばかりが反響し、考えが極端になりやすい状態。",
      "example": "特定のコミュニティで意見が強化され続ける。",
      "category": "社会的影響"
    },
    {
      "term": "AIガバナンス",
      "reading": "えーあいがばなんす",
      "definition": "AIを安全に運用するための仕組み・ルール・監視体制。",
      "example": "AIの品質チェックやデータ管理ルールの整備。",
      "category": "ガバナンス"
    },
    {
      "term": "リスクベースアプローチ",
      "reading": "りすくべーすあぷろーち",
      "definition": "AIのリスクの大きさに応じて対策の強さを変える考え方。",
      "example": "自動運転AIは高リスクなので厳しい管理が必要。",
      "category": "ガバナンス"
    },
    {
      "term": "モニタリング（監視）",
      "reading": "もにたりんぐ",
      "definition": "AIが正しく動いているか定期的にチェックすること。",
      "example": "誤判定が増えていないか監視する。",
      "category": "ガバナンス"
    },
    {
      "term": "トレーサビリティ（追跡可能性）",
      "reading": "とれーさびりてぃ",
      "definition": "AIがどんなデータで学習し、どう判断したかを後から追えるようにすること。",
      "example": "学習データの出どころを記録する。",
      "category": "ガバナンス"
    },
    {
      "term": "ログ管理",
      "reading": "ろぐかんり",
      "definition": "AIの動作記録を残しておくこと。トラブル時の原因調査に必要。",
      "example": "AIの入力・出力を記録する。",
      "category": "ガバナンス"
    },
    {
      "term": "モデルカード（Model Card）",
      "reading": "もでるかーど",
      "definition": "AIモデルの説明書。学習データ・用途・注意点などをまとめた文書。",
      "example": "『このモデルは医療用途には使わないでください』などの記載。",
      "category": "ガバナンス"
    },
    {
      "term": "データシート（Data Sheet）",
      "reading": "でーたしーと",
      "definition": "学習データの説明書。データの出どころ・偏り・注意点をまとめる。",
      "example": "『このデータは特定地域に偏っています』など。",
      "category": "ガバナンス"
    },
    {
      "term": "AI監査（AI Audit）",
      "reading": "えーあいかんさ",
      "definition": "AIがルール通りに動いているかを第三者がチェックする仕組み。",
      "example": "AIの公平性や安全性を外部機関が確認する。",
      "category": "ガバナンス"
    },
    {
      "term": "EU AI Act",
      "reading": "いーゆーえーあいあくと",
      "definition": "EUが定めた世界で最も厳しいAI規制。AIをリスクの高さで分類して管理する。",
      "example": "自動運転AIは高リスク、チャットボットは低リスクなど。",
      "category": "国際ルール"
    },
    {
      "term": "OECD AI原則",
      "reading": "おーいーしーでぃーえーあいげんそく",
      "definition": "国際的に合意されたAIの基本ルール。",
      "example": "公平性・透明性・安全性・プライバシー保護など。",
      "category": "国際ルール"
    },
    {
      "term": "日本のAI戦略",
      "reading": "にほんのえーあいせんりゃく",
      "definition": "日本政府が定めたAI活用の方針。『人間中心のAI社会』がキーワード。",
      "example": "教育・産業・行政でAIを活用する方針。",
      "category": "国際ルール"
    }
  ]
}
