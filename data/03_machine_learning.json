{
  "chapter_id": "03",
  "chapter_title": "機械学習の概要",
  "terms": [
    {
      "term": "教師あり学習",
      "reading": "きょうしありがくしゅう",
      "definition": "正解ラベルつきのデータを使って学習する方法。問題と答えのセットをたくさん見せてパターンを覚える。",
      "example": "犬の写真に「犬」、猫の写真に「猫」とラベルをつけて学習させる。",
      "category": "学習方法"
    },
    {
      "term": "教師なし学習",
      "reading": "きょうしなしがくしゅう",
      "definition": "正解ラベルなしのデータを使い、自動でグループ分けや特徴抽出を行う学習方法。",
      "example": "顧客の購入履歴から似た行動のグループを自動で作る。",
      "category": "学習方法"
    },
    {
      "term": "分類",
      "reading": "ぶんるい",
      "definition": "データをあらかじめ決められたカテゴリに分けるタスク。",
      "example": "メールを「スパム」か「スパムではない」に分ける。",
      "category": "タスク"
    },
    {
      "term": "回帰",
      "reading": "かいき",
      "definition": "未来の数値を予測するタスク。",
      "example": "明日の気温や家の価格を予測する。",
      "category": "タスク"
    },
    {
      "term": "線形回帰",
      "reading": "せんけいかいき",
      "definition": "直線を使って未来の数値を予測する方法。",
      "example": "身長から体重を予測するイメージ。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "ロジスティック回帰",
      "reading": "ろじすてぃっくかいき",
      "definition": "0〜1の確率を出して分類する方法。名前は回帰だが分類に使う。",
      "example": "病気になる確率を予測し、0.7なら「病気」と分類する。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "決定木",
      "reading": "けっていぎ",
      "definition": "質問を順番にしていき、最終的に分類や予測を行うモデル。",
      "example": "『気温は高い？』『雨は降ってる？』と質問して判断する。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "ランダムフォレスト",
      "reading": "らんだむふぉれすと",
      "definition": "複数の決定木を作り、多数決で予測するアンサンブル学習の一種。",
      "example": "10本の木のうち7本が「買う」と言えば「買う」と予測する。",
      "category": "アンサンブル学習"
    },
    {
      "term": "サポートベクターマシン（SVM）",
      "reading": "さぽーとべくたーましん",
      "definition": "データを線や面で分ける方法。境界線から最も近い点との距離（マージン）を最大にする。",
      "example": "犬と猫の写真を線で分けるイメージ。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "マージン",
      "reading": "まーじん",
      "definition": "分類の境界線と最も近いデータ点の距離。広いほど安定した分類ができる。",
      "example": "境界線から遠いほど分類が自信を持てる状態。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "カーネル法",
      "reading": "かーねるほう",
      "definition": "分けにくいデータを高次元に変換して分けやすくする技術。",
      "example": "平面で分けられない丸い形を立体に持ち上げると分けられる。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "カーネルトリック",
      "reading": "かーねるとりっく",
      "definition": "実際に高次元に移動せず、計算だけで高次元に移動したように扱う技。",
      "example": "計算を工夫して、重い処理を省略する。",
      "category": "モデル・アルゴリズム"
    },
    {
      "term": "多クラス分類",
      "reading": "たくらすぶんるい",
      "definition": "3つ以上のカテゴリに分類するタスク。",
      "example": "手書き数字0〜9の分類。",
      "category": "タスク"
    },
    {
      "term": "アンサンブル学習",
      "reading": "あんさんぶるがくしゅう",
      "definition": "複数のモデルを組み合わせて精度を上げる方法。",
      "example": "3人より100人の多数決のほうが当たりやすい。",
      "category": "アンサンブル学習"
    },
    {
      "term": "バギング",
      "reading": "ばぎんぐ",
      "definition": "同じモデルを複数作り、データを少しずつ変えて学習させる方法。",
      "example": "ランダムフォレストで使われる。",
      "category": "アンサンブル学習"
    },
    {
      "term": "ブースティング",
      "reading": "ぶーすてぃんぐ",
      "definition": "前のモデルが間違えたデータを重点的に学習し、少しずつ賢くする方法。",
      "example": "苦手問題を重点的に復習するイメージ。",
      "category": "アンサンブル学習"
    },
    {
      "term": "勾配ブースティング",
      "reading": "こうばいぶーすてぃんぐ",
      "definition": "誤差を少しずつ修正しながらモデルを強化するブースティングの一種。",
      "example": "間違いを少しずつ直していく学習方法。",
      "category": "アンサンブル学習"
    },
    {
      "term": "AdaBoost",
      "reading": "あだぶーすと",
      "definition": "間違えたデータに重みをつけて、次のモデルが重点的に学習する方法。",
      "example": "苦手な問題に重みをつけて復習するイメージ。",
      "category": "アンサンブル学習"
    },
    {
      "term": "ブートストラップサンプリング",
      "reading": "ぶーとすとらっぷさんぷりんぐ",
      "definition": "データを重複ありでランダムに取り出して学習に使う方法。",
      "example": "同じデータが複数回選ばれることもある。",
      "category": "データ処理"
    },
    {
      "term": "K-means",
      "reading": "けーみーんず",
      "definition": "データをK個のグループに分ける教師なし学習の手法。",
      "example": "顧客を3つのグループに分ける場合はK=3。",
      "category": "教師なし学習"
    },
    {
      "term": "PCA（主成分分析）",
      "reading": "ぴーしーえー",
      "definition": "データの次元を減らし、重要な特徴だけを残す方法。",
      "example": "100項目のアンケートを2つの軸にまとめる。",
      "category": "次元削減"
    },
    {
      "term": "t-SNE",
      "reading": "てぃーえすえぬいー",
      "definition": "高次元データを2Dや3Dに可視化する方法。",
      "example": "複雑なデータを散布図のように表示する。",
      "category": "次元削減"
    },
    {
      "term": "トピックモデル（LDA）",
      "reading": "とぴっくもでる",
      "definition": "文章の中に隠れた話題（トピック）を見つける方法。",
      "example": "ニュース記事を『政治』『スポーツ』『経済』に自動分類する。",
      "category": "教師なし学習"
    },
    {
      "term": "コールドスタート問題",
      "reading": "こーるどすたーともんだい",
      "definition": "新しいユーザーや商品にデータが少なく、推薦が難しい問題。",
      "example": "新規ユーザーにおすすめ商品を出しにくい。",
      "category": "推薦システム"
    }
  ]
}
